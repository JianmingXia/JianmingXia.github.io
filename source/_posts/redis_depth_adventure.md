---
title: Redis 深度历险——总结
date: 2018/08/14 19:30:00
tags:
  - Redis
  - 阅读笔记
categories: Redis
---

> 缓存 分布式锁 持久化

## 说在前面

这个是我个人阅读[Redis 深度历险：核心原理与应用实践](https://juejin.im/book/5afc2e5f6fb9a07a9b362527)一文的总结，当然更多的是阅读笔记。在看的过程中也有很多目前还不太明白的，或是目前还没有吃透的，也会放在本文中做一个备忘。

## 基础

### Redis可以做什么？

- 计数器——记录帖子的点赞数、评论数、点击数（hash）
- 排行榜（zset）
- 好友关系——共同好友，使用集合的相关命令
- 记录用户的帖子列表（排序），便于快速显示（zset）
- 记录帖子的相关文章ID，根据内容推荐帖子（List）
- Session缓存
- ...
<!-- more -->

### 不适合做什么？
> 千万不要把Redis当银弹

比如拿Redis去存储用户的基本信息，虽然Redis支持持久化，核心数据还是不要过于依赖Redis。
缓存——存储的热数据，否则放内存中就是浪费资源

### Redis 基础数据结构
[Redis 基础](../redis_base)

## 应用
### 分布式锁
[Redis 分布式锁](../redis_distlock)

### 延时队列

当我们需要执行一个延时任务时：

- 在C++中，直接调用ScheduleService；
- 在NodeJS中，无论是使用setTimeout还是引入其它的库实现。

这些其实都存在一个问题，当我们的服务重启时，这些延时任务就自然丢失了。

#### 实现

基于Redis的有序集合实现
- 使用zadd不断添加延时任务
- 与此同时，使用zrangebyscore筛选出符合条件的任务来执行

### 位图

当我们需要有标志位的使用场景时（是否签到，是否有某接口权限），可以考虑使用位图，能够节省大量的存储空间。 

#### 命令

- getbit
- setbit
- bitcount
- bitpos
- bitop
- bitfiel

#### 注意事项

- 使用bitcount及bitpos指令时，参数[start, end]是字节索引，不是byte位

### HyperLogLog

当我们要统计某个页面的UV时，HyperLogLog会是一个很好的解决方案。

#### 特点

- HyperLogLog提供的是一个不精确的去重计数方案
- 没有判断是否存在的命令

对比与set，数据不够精确。无法判断数据是否存在，只有pfadd, pfcount, pfmerge。但是当数据量上升的时候，空间仅会占12kb。

### 布隆过滤器
与set更类似，可以判断数据是否准备，同样会有一个问题——数据不够准确，有一定误判率

#### 特点

- 当布隆过滤器说某个值存在时，可能不存在
- 当说某个值不存在时，那就肯定不存在

### 简单限流
- 当系统的处理能力有限时，如何阻止计划外的请求？
- 如何控制用户行为，避免垃圾请求？

#### 实现
通过使用有序集合，定期清理数据，来实现限流。
```
def is_action_allowed(user_id, action_key, period, max_count):
    key = 'hist:%s:%s' % (user_id, action_key)
    now_ts = int(time.time() * 1000)  # 毫秒时间戳
    with client.pipeline() as pipe:  # client 是 StrictRedis 实例
        # 记录行为
        pipe.zadd(key, now_ts, now_ts)  # value 和 score 都使用毫秒时间戳
        # 移除时间窗口之前的行为记录，剩下的都是时间窗口内的
        pipe.zremrangebyscore(key, 0, now_ts - period * 1000)
        # 获取窗口内的行为数量
        pipe.zcard(key)
        # 设置 zset 过期时间，避免冷用户持续占用内存
        # 过期时间应该等于时间窗口的长度，再多宽限 1s
        pipe.expire(key, period + 1)
        # 批量执行
        _, _, current_count, _ = pipe.execute()
    return current_count <= max_count
```

#### 限制
如果要做比如 60s内不得超过100W次，这类消耗的存储空间太大了

### 漏斗限流
- https://github.com/brandur/redis-cell

#### 命令
```
CL.THROTTLE user123 15 30 60 1
```

参数说明：
- CL.THROTTLE => 命令名称
- user123 => key
- 15 => 容量
- 30 / 60 => 漏斗速率
- 1 => 需要的容量

#### 返回值
```
(integer) 0   # 0 表示允许，1表示拒绝
(integer) 15  # 漏斗容量
(integer) 14  # 漏斗剩余空间
(integer) -1  # 如果拒绝了，需要多长时间后再试(单位秒)
(integer) 2   # 多长时间后，漏斗完全空出来(单位秒)
```

### GeoHash
地理位置Geo模块，可以用来实现【附近的xx】

计算结果实际上是存储在zset中。

#### 特点

在Redis中使用Geo数据结构，可能在集群环境中会造成迁移时的卡顿现象，建议使用单独Redis实例存储Geo，并且拆分数据，按国家、省份、城市等。

### Scan
与keys对比：

- 复杂度虽然也是 O(n)，但是它是通过游标分步进行的，不会阻塞线程;
- 提供 limit 参数，可以控制每次返回结果的最大条数，limit 只是一个 hint，返回的结果可多可少;
- 同 keys 一样，它也提供模式匹配功能;
- 服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数;
- 返回的结果可能会有重复，需要客户端去重复，这点非常重要;
- 遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的;
- 单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零;

## 原理
### 线程IO模型
- 为什么Redis单线程还这么快？ —— 内存级别的运算
- 单线程如何处理那么多并发客户端连接？——事件轮询（多路复用）、非阻塞IO

### 通信协议
RESP——Redis Serialization Protocol

### 持久化
- 快照：全量备份
- AOF：连续的增量备份，在长期的运行中会越来越大，这样在重启时通过加载AOF日志来进行指令重放恢复时，需要花费极长的时间——定期进行AOF重写，给AOF日志瘦身

#### 快照原理
> 为了不影响线上的业务，需要一边持久化一边响应客户端请求。而在进行内存快照的时候，文件IO操作是不能使用多路复用API的。

Redis使用操作系统的多线程COW（copy on write）机制来实现快照持久化

#### fork(多进程)
持久化时会fork产生一个子进程，快照持久化完全交由子进程来处理，父进程继续处理请求。
在子进程刚产生时，与父进程共享内存中的代码段和数据段。
随着父进程修改操作的持续运行，会有越来越多的共享页面被分离出来。而子进程还是最初产生时的数据，故而称为快照

#### AOF 原理
AOF日志存储的是Redis服务器的顺序指令序列，只存储对内存进行修改的指令。
假如AOF日志记录了自Redis实例创建以来的所有修改指令，我们可以通过对一个空的Redis实例顺序执行所有的指令——即【重放】，恢复Redis当前实例的内存数据。

AOF步骤：
- 收到客户端修改指令后，先进行参数校验
- 参数校验通过，立即将指令文本存储到AOF日志中（先存储到磁盘）
- 最后再执行指令（即使突发宕机了，【重放】也可以恢复数据）

#### AOF 重写

Redis提供bgrewriteaof指令用于AOF日志瘦身：

- 开辟一个子进程对内存进行遍历转换成一系列的Redis操作指令
- 将操作指令序列化到新的AOF日志文件中
- 序列化完毕后，将操作期间内发生的增量AOF日志追加到新的AOF日志中
- 追加完毕后替代旧的AOF日志

#### fsync

当写入AOF文件时，实际上是先将内容写到内核为文件描述符分配的一个内存缓冲中，之后内存会异步将数据刷回到磁盘。

此时就存在一个问题，如果机器突然宕机，AOF日志可能没来得及刷到磁盘中——linux中的glibc提供了fsync(int fd)函数可以将指定文件的内容强制从内核刷到磁盘，只要Redis进程实时调用fsync就可以保证AOF日志不丢失。

但fsync是一个磁盘IO操作，很慢！——通常，在生产环境中，redis每隔1s执行一次fsync操作。

#### Redis 4.0混合持久化

快照与AOF都有一定的缺点：快照容易丢失数据、AOF要使用日志重放，花费时间

在Redis 4.0中，为了解决这些问题，支持混合持久化。

### 管道

> 误解：pipeline是Redis服务器提供的特别技术，用于加速Redis的存取效率。事实上，这个技术的本质是客户端提供的。

对于管道来说，连续的**write**操作基本没有耗时，**read**操作会等待一个网络的来回开销，然后所有的响应消息就都已经回到内核的读缓冲了，后续的read操作可以直接从缓冲中取数据。

### 事务

为了确保连续多个操作的原子性，一个成熟的数据库通常都会有事务支持。

需要明确一点，Redis中的事务与关系数据库中的事务是不同的。
在Redis中，事务相关指令为：

- multi：表示事务的开始
- exec：表示事务的执行
- discard：表示事务的放弃

#### 原子性

需要明确Redis的原子性和关系型数据库是不一样的，当事务执行中间发生失败了，后面的命令还可以继续进行。

语法问题：

- NodeJS：仅使用ioredis测试，如果语法出现问题则全部命令都会执行失败（比如set需要传入key value，只传入了key）

#### 原理

使用multi开启事务后，直到收到exec命令，服务器才开始执行整个事务队列，执行完毕后将所有命令的运行结果返回。
由于Redis单线程特性，在这里我们可以理解为它是原子性的——但实际上，它并不是原子性的。

> 原子性是指事务是一个不可再分割的工作单位，事务中的操作要么都发生，要么都不发生。

Redis的事务在执行的过程中，如果命令执行失败，不会影响后续命令继续执行。

#### 优化

Redis的每个命令发到服务端都会经过一次网络IO，所以当我们使用事务时，可以结合pipeline一起使用，可以将多次IO优化为一次。

#### Watch

之前介绍过分布式锁，需要注意的是，分布式锁实际上是悲观锁——先加锁，再修改资源，再释放锁。
如果大家之前了解过乐观锁：先修改资源，检查资源释放被修改过，如果未被修改，则本次修改成功；如果已被修改，重试即可。

大家在使用Watch的时候，需要先根据场景进行评估——到底是选择Watch还是分布式锁

#### 注意事项

- Redis禁止在multi和exec之间执行watch命令

### Pub/Sub

当我们需要实现：一个生产者负责生产消息，多个消费者同时订阅消息时，可以考虑使用Pub/Sub。

#### 订阅方式

- 名称订阅：如subscribe test
- 模式订阅：如subscribe test.\*

#### 注意事项

- Redis不允许在subscribe的同时还进行其他的操作
- 在消费者挂掉期间，生产者发送的消息彻底丢失

Pub/Sub的问题还是比较多，很难找到适合的应用场景。

#### 补充

Redis 5.0 新增了Stream，有兴趣的可以看一下。

### 小对象压缩

#### 32bit vs 64bit

如果使用32bit进行编译，内部所有指针所占用的空间会减少一半。

#### 小对象压缩存储 (ziplist)

压缩列表部分

#### 内存回收机制

Redis并不总是可以将空闲内存立即归还操作系统。

原因是操作系统回收内存是以页为单位，即使你删除了1GB的key，但只有页上有一个key在使用，就不能被回收——虽然无法被回收，但是这部分的空闲内存可以重用。

### 主从同步

CAP：

- 一致性
- 可用性
- 分区容忍性

网络分区发生时，一致性和可用性两难全

#### 最终一致

因为Redis的主从数据是异步同步的，故而不满足【一致性】。当客户端在Redis主节点修改数据后，即使主从断开，但主节点依然能提供服务，故而满足【可用性】。

Redis会保证【最终一致性】，从节点会努力追赶主节点。

#### 主从同步

Redis支持主从同步和从从同步。

#### 增量同步

主节点会将修改指令记录在本地的内存buffer中，然后异步将buffer中的指令同步到从节点，从节点一遍执行同步的指令流，一边向主节点同步偏移量。

但是内存的buffer是有限的，旧有的修改指令未同步被覆盖后，从节点就无法直接通过指令流来同步——快照同步

#### 快照同步

快照同步是非常耗费资源的

快照同步和增量同步结合使用，注意buffer大小，避免每次都是快照同步。

#### 增加从节点

先进行快照同步，再进行增量同步

#### 无盘复制

进行快照同步时，文件IO操作会消耗较长时间——无盘复制是指主节点通过套接字将快照内容发送到从节点。

#### Wait指令

Redis 的复制是异步进行的，Wait指令可以让异步复制变为同步，确保系统的强一致性（不严格）

假设出现网络分区，wait可能会被阻塞，失去可用性。

#### 小结

如果Redis只做缓存，没有复制功能没有太大关系，挂了直接重启即可。

如果使用Redis的持久化功能，在做主从复制时，就得好好考虑一下。

## 总结

还有一些是目前从文中获取的知识，但是还没有验证过的：

- Geo
- 持久化部分——glibc 

## 参考
- https://juejin.im/book/5afc2e5f6fb9a07a9b362527